#+Title: Evaluating Navigational RDF Queries over Web
#+Author: Baier, Daroch, Reutter and Vrgoc
#+Email: {jabaier,jreutter,dvrgoc}@ing.puc.cl, ddaroch@uc.cl
#+Web: doge.ing.puc.cl/Dietrich/Slides/evaluating_nav_queries
#+Language: en
#+Date: 2017-07-06

* Setup                                                            :noexport:
#+SEQ_TODO: TODO REVIEW | DONE
#+REVEAL_ROOT: http://localhost:8000
#+REVEAL_HEAD_PREAMBLE: <script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/d3/4.9.1/d3.min.js'></script>

# ##Local Variables:
# ##eval: (add-hook 'after-save-hook (org-reveal-export-to-html))
# ##eval: (add-hook 'after-save-hook (org-pandoc-export-to-beamer-pdf))
# ##End:


* Config                                                          :noexport:
#+STARTUP: overview

** Numbering
#+OPTIONS: toc:nil
# Remove numbering from sections and subsections
#+OPTIONS: num:nil

** Reveal
#+REVEAL_HLEVEL: 2
#+REVEAL_SPEED: 2
#+OPTIONS: reveal_slide_number:h.v

# Adding plugings without their dependencies might break your slides
#+REVEAL_EXTRA_JS: { src: 'plugin/math/math.js', async: true }, { src: 'plugin/zoom-js/zoom.js', async: true }
#+REVEAL_PLUGINS: (highlight markdown notes)


*** Looks
 #+REVEAL_TRANS: slide
 # Theme (black moon night blood)
 #+REVEAL_THEME: black
 # Target 1366x768, 16:9 and not far from 1024x768 widely used on projectors
 #+OPTIONS: reveal_width:1366 reveal_height:768
 # #+REVEAL_EXTRA_CSS: custom.css
*** Reveal
 #+OPTIONS: reveal_center:t
 #+OPTIONS: reveal_progress:t
 #+OPTIONS: reveal_history:nil
 #+OPTIONS: reveal_control:t
 #+OPTIONS: reveal_rolling_links:t
 #+OPTIONS: reveal_keyboard:t
 #+OPTIONS: reveal_overview:t

** Beamer
#+BEAMER_THEME: Rochester [height=20pt]

# #+OPTIONS: H:2
# #+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t


* Introduction
  :PROPERTIES:
  :reveal_background: images/lod-1080-fade.png
  :reveal_background_trans: slide
  :END:

** Motivation
*** Sharing across databases

		#+ATTR_REVEAL: :frag (appear)
		- Information on relational databases is hard to share
			- Different format, schema and access policies
			- Sharing problems cause data to become outdated
		- A different approach is needed


#+LaTeX: \note{
#+BEGIN_NOTES
Relational databases are a closed source of information, which makes it hard to
share

Duplicating the shared data on all databases does not makes much sense
 and it can easily become stale as it won't be maintained by the real owner
#+END_NOTES
#+LaTeX: }

*** A Web-like approach
		The Web provides linked documents with human readable information

		#+ATTR_REVEAL: :frag (appear)
		- Documents are linked
			- Real owners can update the data
			- Documents can be navigated across different servers
		- It's distributed
			- Can scale-out

** Linked Data
*** One Database to rule them all
		LD movement proposes using a graph made of IRIs and strings

		#+ATTR_REVEAL: :frag (appear)
		- Uses links to data instead of copies
		- Uses IRIs as data identifiers
		- Uses IRIs as relation identifiers
			- And suggests collection of relations to use


#+LaTeX: \note{
#+BEGIN_NOTES
Following the web, LD proposes using a graph, but instead of documents and
links, it explicitly uses identifiers as things rather than only identifiers of
documents
#+END_NOTES
#+LaTeX: }

*** Resource Description Framework
		Defines the layout of the data

		#+ATTR_REVEAL: :frag (appear)
		- An RDF triple is a tuple $(S, P, O)$
			- $Subject$   is an IRI or a string
			- $Predicate$ is an IRI representing a relation
			- $Object$    is an IRI or a string
		  - It's essentially the unit of information
		- Data is meant to be retrieved from the internet
			- Open-world assumption must be used


#+LaTeX: \note{
#+BEGIN_NOTES
RDF is a specification on of the data layout
An RDF triple is the essential unit of information, it relates some objects
using a predicate.

What is really interesting about RDF, is that IRIs become identifiers for
the data, this enables identifiers to be shared across databases, and also to
have a common vocabulary on the relations.
This change allows different databases to be combined without the need for human
review of the schemas compatibility. No conversions are needed.
#+END_NOTES
#+LaTeX: }

*** An example
#+BEGIN_SRC txt
prefix dblpAuthor: <http://dblp.l3s.de/d2r/resource/authors/>
prefix dblpConf:   <http://dblp.l3s.de/d2r/resource/publications/conf/>

dblpConf:sigmod/Stonebraker90    dc:creator  dblpAuthor:Michael_Stonebraker
dblpConf:sigmod/Stonebraker90  rdfs:label    "The Postgres DBMS."
dblpAuthor:Michael_Stonebraker foaf:name     "Michael Stonebraker"
#+END_SRC

*** Why RDF?

		#+ATTR_REVEAL: :frag (appear)
		- Different databases can be trivially joined
			- No schema compatibility problems or conversions.
		- Database can be sharded

** Querying Linked Data
*** A data model is not enough
		Databases must be queried to be useful


#+LaTeX: \note{
#+BEGIN_NOTES
RDF is a data model for storing information, but having information is worthless
without a way to query it
So far LD proposes a model for storing information in a distributed fashion.
#+END_NOTES
#+LaTeX: }


*** SPARQL
		A SQL-like language for querying and modifying graph databases

		#+ATTR_REVEAL: :frag (appear)
		- A query language
			- Queries are RDF graphs with variables and restrictions
			- Answers are computed by pattern matching
		- SPARQL servers provide
			- An SPARQL endpoint to consume or update RDF data
			- A store for the data


#+LaTeX: \note{
#+BEGIN_NOTES
SPARQL is a language for querying graphs, it looks like SQL and relies on
subgraph matching specifying queries.

SPARQL servers provide endpoints (services) to interact
#+END_NOTES
#+LaTeX: }


*** Problems with SPARQL

		#+ATTR_REVEAL: :frag (appear)
		- Querying multiple servers is hard
			- Query federation allows specifying multiple servers
				- Lacks discoverability
				- Queries are harder to write
		- Computation is done completely server-side
			- Exposing SPARQL endpoints is troublesome
			- Queries can be hard
				- Subgraph matching is NP-complete


#+LaTeX: \note{
#+BEGIN_NOTES
SPARQL has a few problems.

Servers must handle too much of the complexity as the only task for clients is
to send the query and receive the final answer.
#+END_NOTES
#+LaTeX: }

* Navigational Queries
** Navigation
*** Searching data the way you browse for it

		#+ATTR_REVEAL: :frag (appear)
		- You don't know which server has the answer
			- From a starting point you follow links onto your answers
		- Servers just offer data
			- You do the computation and ask for data on the fly
		- You don't know whether you see all the data
			- Open-world semantics are intrinsic
			- You probably can't have all of it


#+LaTeX: \note{
#+BEGIN_NOTES
While SPARQL seems too centralized for LD, we have been using the web to publish
distributed documents, and have been accessing them by manually going through
them and finding our way though the links.
#+END_NOTES
#+LaTeX: }

*** Property Paths
		Property paths allow expressing composed relations using regular expressions
		over IRIs and their inverses

		#+ATTR_REVEAL: :frag (appear)
		- Expressive and easy to compute
		- Regular expressions are already widely studied
		- SPARQL supports them too, but
			- Lacks the discoverability that PP allow
			- Patterns can prove the same relation in many ways


#+LaTeX: \note{
#+BEGIN_NOTES
Property Paths allow to express many interesting queries while still being easy
to compute.

Property Paths were included on SPARQL 1.1, but they don't help with SPARQL's
discoverability problems and as they are used as patterns rather than relations
they lead to too many answers.
If you are interested on this bad behavior, there's an example at the end
#+END_NOTES
#+LaTeX: }


*** Property Path examples

#+BEGIN_LaTeX
\begin{align*}
(successor)^*&  \\
(children + parent^{-})& \cdot name  \\
(creator^{-} \cdot creator)^+& \cdot name  \\
(acted\_in \cdot acted\_in^{-})^+& \cdot directed \cdot name
\end{align*}
#+END_LaTeX


** Automata
*** Definition
		Property Path Automata

		#+ATTR_REVEAL: :frag (appear)
		- An automaton over alphabet of IRIs and their inverses
		- Matching requires an initial IRI to pair with the initial State
			- Computing matches needs dereferencing IRIs
			- Computations looks like resolving a search problem
		- Can be enhanced with filtering on States and Transitions

*** Example

#+reveal_html: <img class="figure" src="graphics/coauth-name.png"/>
#+LaTeX: \center\includegraphics[width=\textwidth]{graphics/coauth-name.png}

** Search
*** Matching as a Search Problem
		Matching resembles a search problem

		#+ATTR_REVEAL: :frag (appear)
		- The problem is a Search Problem over $RDFGraph \times States$
		- But not only one shortest-path is needed
			- It's easy to tweak the search to get all shortest paths

*** Searching with an Automaton

#+reveal_html: <div class="stretch">
#+reveal_html: <iframe data-src="coauthor.html" width="100%" height="100%"></iframe>
#+reveal_html: </div>
#+LaTeX: \href{http://localhost:8000/coauthor.html}{link}


*** Advantages of using a Search Problem

		#+ATTR_REVEAL: :frag (appear)
		- Relations are only proved once
			- Answers are brief
			- Requires remembering visited $(node, state)$ pairs
		- Search is agnostic from the source of the data
			- You just need a way to dereference
			- Contacting new servers on-the-fly is free

*** Using query information to speed up search

		#+ATTR_REVEAL: :frag (appear)
		- Property Path matching is was seen as a recursive algorithm
			- That leads a DFS implementation
			- No guarantees on solution size or their order
		- Search for shortest paths needed BFS, but it's too slow
		- Using query information allows to use $A^*$
			- 'Right' mix between both approaches

*** Heuristic
		Distances to accepting states are lower bounds for finding answers

#+reveal_html: <img class="fragment figure" src="graphics/coauth-name-h.png"/>
#+LaTeX: \pause\center\includegraphics[width=\textwidth]{graphics/coauth-name-h.png}


*** Implementation details

		#+ATTR_REVEAL: :frag (appear)
		 - Parallel expansions
			 - Instead of expand the top f-value, try to expand all of them
			 - A Message-passing implementation would do even better
		 - The heuristic can be precomputed
			 - Little gain as CPU is far from being a constraint
		 - Early goal declaration
			 - Declare goals when before adding nodes to the queue
			 - Avoid adding dead-end nodes
				 - Implemented by modifying the heuristic


*** Heuristic for using Early Expansions
		Expanding a $(node, state)$ discovers nodes paired with successor states

#+reveal_html: <img class="figure" src="graphics/coauth-name-h.png"/>
#+reveal_html: <img class="fragment figure" src="graphics/coauth-name-sh.png"/>
#+LaTeX: \center\includegraphics[width=\textwidth]{graphics/coauth-name-h.png}
#+LaTeX: \pause\center\includegraphics[width=\textwidth]{graphics/coauth-name-sh.png}


#+LaTeX: \note{
#+BEGIN_NOTES
This is similar to the path-max idea that a node can only be as promising as the
nodes it leads to considering the cost to reach them.
#+END_NOTES
#+LaTeX: }


** Evaluation
*** Experiment setup
		- Search bounds
			- Stop if $1000$ answers are found
			- Stop if $100000$ triples are retrieved
			- Stop after $10$ minutes searching
		- Ran on i5-4670 quad-core with 4GiB RAM
		- Servers queried
			- YAGO
			- DBLP
			- DBpedia
			- LinkedMovie Database

*** Sample query - CoAuthor
#+reveal_html: <img class="figure" src="graphics/q1.png"/>
#+LaTeX: \center\includegraphics[width=0.8\textwidth]{graphics/q1.pdf}

*** Sample query - Bacon Number
#+reveal_html: <img class="figure" src="graphics/q2.png"/>
#+LaTeX: \center\includegraphics[width=0.8\textwidth]{graphics/q2.pdf}

*** Sample query - NATO
#+reveal_html: <img class="figure" src="graphics/q3.png"/>
#+LaTeX: \center\includegraphics[width=0.8\textwidth]{graphics/q3.pdf}

*** Results summary
		We measured 11 queries, the table counts on how many queries the algorithms
		had better performance.

|--------------------+----+-----+-----|
| Measure            | A* | BFS | DFS |
|--------------------+----+-----+-----|
| Requests / Answers | 11 |   3 |   4 |
| Time / Answers     | 11 |   3 |   4 |
|--------------------+----+-----+-----|

*** Experiment discussion
		- Little CPU needed
		- Memory used is linear on the dereferenced data
		- Time dominated by dereference time
			- It's important to do good and parallel scheduling
		- Optimizing dereference should yield to vast improvements
			- Parallel and reusable connections
			- Compression
			- Simple queries (Subset of Linked Data Fragments)

* Questions
* Extra
** TODO Informed search is superior
** TODO Heuristic optimization demo
** TODO Evaluation
*** TODO Experiments
Experiments are available on the repo
** Paths prove relation
*** Computing all of them seems pointless
		Looking for all patterns that match can be too much
		 #+ATTR_REVEAL: :frag (appear)
		 - A toy database:
			 - Alphabet and a less than relation
		 - Which patterns match $a \cdot lessThan^* \cdot X$?
			 - a < z
			 - a < b < c < ... < z
			 - There's one match per subset of $\{b..y\}$
		 - Less or equal leads to infinite matches!
		 - Is the data flawed?
			 - On the internet you won't control it. You must avoid this

* Thanks
* Old                                                             :noexport:

#+BEGIN_NOTES
Imagine you are given a flash drive with the contents of the internet, but at
the cost of not having internet anymore. Would that be useful?
Great part of the value of the internet is on being able to access living
information. Most of the information on that flash drive will become irrelevant
or stale
Databases face a similar problem, they don't usually have access to the outside
world.
#+END_NOTES
